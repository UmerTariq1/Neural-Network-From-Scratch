{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      #used only for np.random and np.zeros\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = [1,2,3,2.5]\n",
    "# batchInput = [ [1,2,3,2.5], [2.0,5.0,-1.0,2.0], [-1.5,2.7,3.3,-0.8]] \n",
    "              \n",
    "# weights = [ [0.2, 0.8, -0.5, 1.0], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "# bias = [2,3,0.5]\n",
    "\n",
    "\n",
    "# weights2 = [ [0.1,-0.14,0.5,0.1], [-0.5,0.12,-0.33,0.1],  [-0.44,0.73,-0.13]]\n",
    "# bias2 = [-1,2,-0.5]\n",
    "\n",
    "\n",
    "# [0.1,0.1,0.1]\n",
    "\n",
    "# weight's outer shape tells you size of output's total number of neuron in next layer\n",
    "# weight's inner shape tells you shape of input's each neuron \n",
    "# in above case, next layer main 3 neurons hain and previous layer main 4 neurons hain\n",
    "# input k outer dimension, in above case which is 3..is the number of batch inputs we are processing together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrixTranspose( matrix ):\n",
    "    if not matrix: return []\n",
    "    return [ [ row[ i ] for row in matrix ] for i in range( len( matrix[ 0 ] ) ) ]\n",
    "\n",
    "def getDimension(a):\n",
    "    if type(a) == list or type(a) == np.ndarray:\n",
    "        return [len(a)] + getDimension(a[0])\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    \n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        #if you want the same weights as sentdex then use below 2 lines (n_inputs,n_neurons). and then transpose the matrix since my implementation need (n_neurons,n_inputs)\n",
    "        self.weightsSet = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
    "        self.weightsSet = np.array(self.weightsSet).T        #this is just to initialize weights same as in the sentdex tutorial. no other purpose.\n",
    "\n",
    "        #if you just want implementation and not following sentdex output then use below line : (n_inputs,n_neurons)\n",
    "        #self.weightsSet = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
    " \n",
    "        self.bias = np.zeros((n_neurons,)) \n",
    "\n",
    "        print(\"self.weights shape : \", getDimension(self.weightsSet))\n",
    "        print(\"self.bias shape : \", getDimension(self.bias))\n",
    "        \n",
    "    def forward(self,batchInput):\n",
    "        self.batchInput = batchInput\n",
    "        print(\"Input shape : \", getDimension(batchInput))\n",
    "        self.output = self.ProcessBatchInput()\n",
    "#         self.output = np.dot(batchInput,self.weightsSet.T)\n",
    "        \n",
    "    def ProcessBatchInput(self):\n",
    "        output = []\n",
    "        inputNumber=0\n",
    "        for input in self.batchInput:\n",
    "            output.append(self.CalculateOutputForLayer(input))\n",
    "            inputNumber+=1\n",
    "        return output\n",
    "    \n",
    "    '''\n",
    "    @params\n",
    "    input =  list of numbers\n",
    "    weights = list of lists.\n",
    "    bias  =  list of numbers\n",
    "    @output:\n",
    "    output = list of numbers.representing the output for one neuron from the whole previous layer\n",
    "    '''\n",
    "\n",
    "    def CalculateOutputForLayer(self,input):\n",
    "        output = []\n",
    "        numConnections = len(self.weightsSet)       #because weights outer layer tells us how many neurons are there in next level\n",
    "        for index in range(numConnections):\n",
    "            output.append(self.CalculateOutputForOneNeuron(input,self.weightsSet[index],self.bias[index]))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    @params\n",
    "    input = list of numbers\n",
    "    weights = list.\n",
    "    bias = numbers\n",
    "    @output:\n",
    "    output = number. representing the output for one neuron from one neuron\n",
    "    '''\n",
    "\n",
    "    def CalculateOutputForOneNeuron(self,input,weights,bias):\n",
    "        output = self.dotProduct(input,weights)\n",
    "        output += bias\n",
    "        return round(output,3)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    @params\n",
    "    firstList = a lsit\n",
    "    secondList = a lsit\n",
    "    @output:\n",
    "    outputList = a number\n",
    "    '''\n",
    "\n",
    "    def dotProduct(self,firstList,secondList):\n",
    "        outputList = 0\n",
    "        for i,j in zip(firstList,secondList):\n",
    "            outputList += (i*j)\n",
    "        return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationRelu:\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weights shape :  [5, 2]\n",
      "self.bias shape :  [5]\n",
      "Input shape :  [300, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[300, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X, y = spiral_data(100, 3)\n",
    "\n",
    "layer1 = DenseLayer(2,5) \n",
    "layer1.forward(X)\n",
    "\n",
    "activation1 = ActivationRelu() \n",
    "activation1.forward(layer1.output)\n",
    "\n",
    "getDimension(activation1.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# earlier code for checking wiehout aqctivation function \n",
    "classBatchInput =[ [1,2,3,2.5], \n",
    "                  [2.0,5.0,-1.0,2.0], \n",
    "                   [-1.5,2.7,3.3,-0.8]] \n",
    "\n",
    "\n",
    "print(\"Layer 1 : \")\n",
    "layer1 = DenseLayer(4,5)\n",
    "layer1.forward(classBatchInput)\n",
    "print(layer1.output)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Layer 2 : \")\n",
    "layer2 = DenseLayer(5,2)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#earlier code for verifying forward pass\n",
    "\n",
    "x1 = np.dot(layer1.batchInput,layer1.weightsSet.T) + layer1.bias\n",
    "# x2 = np.dot(x1,layer2.weightsSet.T) + layer2.bias\n",
    "# x1,x2,layer1.weightsSet\n",
    "layer1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(\"Shape of input \" , getDimension(input))\n",
    "# print(\"Shape of batchnInput \" , getDimension(batchInput))\n",
    "# print(\"Shape of weights1 \" , getDimension(weights))\n",
    "# print(\"Shape of bias \" , getDimension(bias))\n",
    "# # print(\"Shape of weights2 \" , getDimension(weights2))\n",
    "\n",
    "# layerOutput1 = ProcessBatchInput(batchInput,weights,bias)\n",
    "\n",
    "# print(\"Shape of Layer 1 \" , getDimension(layerOutput1))\n",
    "# print(\"Layer 1 : \" , layerOutput1)\n",
    "\n",
    "# # layerOutput2 = ProcessBatchInput(layerOutput1,weights2,bias2)\n",
    "\n",
    "# # print(\"Shape of Layer 2 \" , getDimension(layerOutput2))\n",
    "# # print(\"Layer 2 \" , layerOutput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(parameter1):\n",
    "    print(parameter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        self.parameter=5\n",
    "    def classFunction(self):\n",
    "        func(self.parameter)\n",
    "        func(parameter)        \n",
    "\n",
    "        \n",
    "obj = test()\n",
    "obj.classFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
