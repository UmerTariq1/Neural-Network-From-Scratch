{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data  # See for code: https://gist.github.com/Sentdex/454cb20ec5acf0e76ee8ab8448e6266c\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "X, y = spiral_data(100, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classBatchInput =[ [1,2,3,2.5], \n",
    "                  [2.0,5.0,-1.0,2.0], \n",
    "                   [-1.5,2.7,3.3,-0.8]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weights shape :  [4, 5]\n",
      "self.bias shape :  [1, 5]\n",
      "Input shape :  [3, 4]\n",
      "[[ 0.17640524  0.04001572  0.0978738   0.22408931  0.1867558 ]\n",
      " [-0.09772779  0.09500884 -0.01513572 -0.01032189  0.04105985]\n",
      " [ 0.01440436  0.14542735  0.07610377  0.0121675   0.04438632]\n",
      " [ 0.03336744  0.14940791 -0.02051583  0.03130677 -0.08540957]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "layer1 = Layer_Dense(4,5)\n",
    "layer1.forward(np.array(classBatchInput))\n",
    "print(layer1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weights shape :  [4, 5]\n",
      "self.bias shape :  [5]\n",
      "Input shape :  [3, 4]\n",
      "[[0.17640524, 0.04001572, 0.0978738, 0.22408931, 0.1867558], [-0.09772779, 0.09500884, -0.01513572, -0.01032189, 0.04105985], [0.01440436, 0.14542735, 0.07610377, 0.0121675, 0.04438632], [0.03336744, 0.14940791, -0.02051583, 0.03130677, -0.08540957]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "layer1umer = DenseLayer_umer(4,5)\n",
    "layer1umer.forward(classBatchInput)\n",
    "print(layer1umer.weightsSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        \n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        print(\"self.weights shape : \", getDimension(self.weights))\n",
    "        print(\"self.bias shape : \", getDimension(self.biases))\n",
    "    def forward(self, inputs):\n",
    "        print(\"Input shape : \", getDimension(inputs))\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDimension(a):\n",
    "    if type(a) == list or type(a) == np.ndarray:\n",
    "        return [len(a)] + getDimension(a[0])\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer_umer:\n",
    "    \n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "#         self.weightsSet = 0.10 * np.random.randn(n_neurons,n_inputs)\n",
    "        self.weightsSet = [[ 0.17640524 , 0.04001572 , 0.0978738,   0.22408931 , 0.1867558 ],\n",
    "                         [-0.09772779 , 0.09500884, -0.01513572 ,-0.01032189,  0.04105985],\n",
    "                         [ 0.01440436 , 0.14542735,  0.07610377,  0.0121675 ,  0.04438632],\n",
    "                         [ 0.03336744 , 0.14940791, -0.02051583,  0.03130677 ,-0.08540957]]\n",
    "        self.bias = np.zeros((n_neurons,)) \n",
    "\n",
    "        print(\"self.weights shape : \", getDimension(self.weightsSet))\n",
    "        print(\"self.bias shape : \", getDimension(self.bias))\n",
    "        \n",
    "    def forward(self,batchInput):\n",
    "        self.batchInput = batchInput\n",
    "        print(\"Input shape : \", getDimension(batchInput))\n",
    "        self.output = self.ProcessBatchInput()\n",
    "#         self.output = np.dot(batchInput,self.weightsSet.T)\n",
    "        \n",
    "    def ProcessBatchInput(self):\n",
    "        output = []\n",
    "        inputNumber=0\n",
    "        for input in self.batchInput:\n",
    "            output.append(self.CalculateOutputForLayer(input))\n",
    "            inputNumber+=1\n",
    "        return output\n",
    "    \n",
    "    '''\n",
    "    @params\n",
    "    input =  list of numbers\n",
    "    weights = list of lists.\n",
    "    bias  =  list of numbers\n",
    "    @output:\n",
    "    output = list of numbers.representing the output for one neuron from the whole previous layer\n",
    "    '''\n",
    "\n",
    "    def CalculateOutputForLayer(self,input):\n",
    "        output = []\n",
    "        numConnections = len(self.weightsSet)       #because weights outer layer tells us how many neurons are there in next level\n",
    "        for index in range(numConnections):\n",
    "            output.append(self.CalculateOutputForOneNeuron(input,self.weightsSet[index],self.bias[index]))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    @params\n",
    "    input = list of numbers\n",
    "    weights = list.\n",
    "    bias = numbers\n",
    "    @output:\n",
    "    output = number. representing the output for one neuron from one neuron\n",
    "    '''\n",
    "\n",
    "    def CalculateOutputForOneNeuron(self,input,weights,bias):\n",
    "        output = self.dotProduct(input,weights)\n",
    "        output += bias\n",
    "        return round(output,3)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    @params\n",
    "    firstList = a lsit\n",
    "    secondList = a lsit\n",
    "    @output:\n",
    "    outputList = a number\n",
    "    '''\n",
    "\n",
    "    def dotProduct(self,firstList,secondList):\n",
    "        outputList = 0\n",
    "        for i,j in zip(firstList,secondList):\n",
    "            outputList += (i*j)\n",
    "        return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
